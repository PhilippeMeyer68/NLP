{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "Disaster tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation of necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in c:\\users\\phili\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phili\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture of the dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to dataset\n",
    "#CHANGE AS NEEDED\n",
    "df=pd.read_csv (r'C:\\Users\\phili\\Documents\\Machine Learning\\Kaggle\\NLP\\train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Size and first lines of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset : (7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of the dataset :\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Delete unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"id\"]\n",
    "del df[\"keyword\"]\n",
    "del df[\"location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower casing\n",
    "def lower_casing(text):\n",
    "    return text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing of url and html\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def tokenization(text):\n",
    "    token=[]\n",
    "    current=\"\"\n",
    "    for i in range(len(text)):\n",
    "        if text[i]==\" \":\n",
    "            token.append(current)\n",
    "            current=\"\"\n",
    "        else:\n",
    "            current=current+text[i]\n",
    "    token.append(current)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(col):\n",
    "    col = lower_casing(col)\n",
    "    col = col.apply(lambda text: remove_punctuation(text))\n",
    "    col = col.apply(lambda text: remove_stopwords(text))\n",
    "    col = col.apply(lambda text: stem_words(text))\n",
    "    col = col.apply(lambda text: remove_urls(text))\n",
    "    col = col.apply(lambda text: remove_html(text))\n",
    "    col = col.apply(lambda text: tokenization(text))\n",
    "    return col\n",
    "\n",
    "df[\"text\"]=textProcessing(df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perspect', 'grate', 'dead', 'critic', 'write', 'contribut', 'studi', 'httptcofmu0fnumxf', 'httptcoaggryhvxkr'] 1\n"
     ]
    }
   ],
   "source": [
    "rd=random.randint(0,len(df[\"target\"]))\n",
    "print(df[\"text\"][rd],df[\"target\"][rd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(df):\n",
    "    dictfreq={}\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df[\"text\"][i])):\n",
    "            if df[\"text\"][i][j] not in dictfreq:\n",
    "                if df[\"target\"][i]==1:\n",
    "                    dictfreq[df[\"text\"][i][j]]=[0,1]\n",
    "                else:\n",
    "                    dictfreq[df[\"text\"][i][j]]=[1,0]\n",
    "            else:\n",
    "                if df[\"target\"][i]==1:\n",
    "                    dictfreq[df[\"text\"][i][j]][1]+=1\n",
    "                else:\n",
    "                    dictfreq[df[\"text\"][i][j]][0]+=1\n",
    "    return dictfreq\n",
    "\n",
    "dictfreq=createDict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, dictfreq):\n",
    "    x =[0,0]\n",
    "    for word in tweet:\n",
    "        if word in dictfreq.keys():\n",
    "            x[0] += dictfreq[word][1]\n",
    "            x[1] += dictfreq[word][0]\n",
    "    return x\n",
    "\n",
    "newcol1=[]\n",
    "newcol2=[]\n",
    "\n",
    "for i in range(len(df[\"text\"])):\n",
    "    temp= extract_features(df[\"text\"][i], dictfreq)\n",
    "    newcol1.append(temp[0])\n",
    "    newcol2.append(temp[1])\n",
    "    \n",
    "df[\"new1\"]=newcol1\n",
    "df[\"new2\"]=newcol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>new1</th>\n",
       "      <th>new2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13000, peopl, receiv, wildfir, evacu, order, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  new1  new2\n",
       "0  [deed, reason, earthquak, may, allah, forgiv, us]       1   194   156\n",
       "1       [forest, fire, near, la, rong, sask, canada]       1   401   121\n",
       "2  [resid, ask, shelter, place, notifi, offic, ev...       1   247   124\n",
       "3  [13000, peopl, receiv, wildfir, evacu, order, ...       1   434   145\n",
       "4  [got, sent, photo, rubi, alaska, smoke, wildfi...       1   195   215"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"text\"]\n",
    "\n",
    "y=df[\"target\"].values\n",
    "df=df.loc[:, df.columns != \"target\"]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train: 0.7964008932089847\n"
     ]
    }
   ],
   "source": [
    "y_pred=regressor.predict(df)\n",
    "print(\"Accuracy on the train:\", accuracy_score(y_pred,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to dataset\n",
    "#CHANGE AS NEEDED\n",
    "sub=pd.read_csv (r'C:\\Users\\phili\\Documents\\Machine Learning\\Kaggle\\NLP\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sub[\"id\"]\n",
    "del sub[\"keyword\"]\n",
    "del sub[\"location\"]\n",
    "\n",
    "sub[\"text\"] = textProcessing(sub[\"text\"])\n",
    "\n",
    "newcol1=[]\n",
    "newcol2=[]\n",
    "\n",
    "for i in range(len(sub[\"text\"])):\n",
    "    temp= extract_features(sub[\"text\"][i], dictfreq)\n",
    "    newcol1.append(temp[0])\n",
    "    newcol2.append(temp[1])\n",
    "    \n",
    "sub[\"new1\"]=newcol1\n",
    "sub[\"new2\"]=newcol2\n",
    "\n",
    "del sub[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission_pred=regressor.predict(sub)\n",
    "y_submission_pred=y_submission_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "# CHANGE AS NEEDED\n",
    "export=pd.read_csv (r'C:\\Users\\phili\\Documents\\Machine Learning\\Kaggle\\NLP\\test.csv')\n",
    "export=pd.DataFrame(export[\"id\"])\n",
    "export[\"target\"]=y_submission_pred\n",
    "export.to_csv (r'C:\\Users\\phili\\Documents\\Machine Learning\\Kaggle\\NLP\\export_sub.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
